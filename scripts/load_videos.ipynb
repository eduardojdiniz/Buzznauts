{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a   href=\"https://colab.research.google.com/github/eduardojdiniz/Buzznauts/blob/7545997973bbd34bc675c27391685bc82fa16332/scripts/Example_loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Buzznauts GitHub Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duecredit --quiet\n",
    "!pip install nilearn --quiet\n",
    "!pip install numpy --quiet\n",
    "!pip install matplotlib --quiet\n",
    "!pip install nibabel --quiet\n",
    "!pip install decord --quiet\n",
    "!pip install tqdm --quiet\n",
    "\n",
    "\n",
    "!pip install opencv --quiet\n",
    "!git clone https://github.com/eduardojdiniz/Buzznauts --quiet\n",
    "!git clone https://github.com/Neural-Dynamics-of-Visual-Cognition-FUB/Algonauts2021_devkit.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Buzznauts Module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Buzznauts.Buzznauts as buzz\n",
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting\n",
    "from tqdm import tqdm\n",
    "\n",
    "fsaverage = datasets.fetch_surf_fsaverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Enter the dropbox link\n",
    "dropbox_link = 'https://www.dropbox.com/s/agxyxntrbwko7t1/participants_data.zip?dl=1' # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run the cell\n",
    "import requests, zipfile, io\n",
    "\n",
    "# Use the dropbox link to download the data\n",
    "print(f\"Dropbox link: {dropbox_link}\")\n",
    "\n",
    "if dropbox_link:\n",
    "  fname1 = 'participants_data_v2021'\n",
    "  fname2 = 'AlgonautsVideos268_All_30fpsmax'\n",
    "  if not os.path.exists(fname1) or not os.path.exists(fname2):\n",
    "    print('Data downloading...')\n",
    "    r = requests.get(dropbox_link)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall()\n",
    "    print('Data download is completed.')\n",
    "  else:\n",
    "    print('Data are already downloaded.')\n",
    "\n",
    "\n",
    "  url = 'https://github.com/Neural-Dynamics-of-Visual-Cognition-FUB/Algonauts2021_devkit/raw/main/example.nii'\n",
    "  fname = 'example.nii'\n",
    "  if not os.path.exists(fname):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    with open(fname, 'wb') as fh:\n",
    "      fh.write(r.content)\n",
    "  else:\n",
    "    print(f\"{fname} file is already downloaded.\")\n",
    "\n",
    "else:\n",
    "  print('You need to submit the form and get the dropbox link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Utility functions for data loading\n",
    "def save_dict(di_, filename_):\n",
    "  with open(filename_, 'wb') as f:\n",
    "      pickle.dump(di_, f)\n",
    "\n",
    "def load_dict(filename_):\n",
    "  with open(filename_, 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    ret_di = u.load()\n",
    "    # print(p)\n",
    "    # ret_di = pickle.load(f)\n",
    "  return ret_di\n",
    "\n",
    "\n",
    "def visualize_activity(vid_id,sub):\n",
    "  # Setting up the paths for whole brain data\n",
    "  fmri_dir = './participants_data_v2021'\n",
    "  track = \"full_track\"\n",
    "\n",
    "  # get the right track directory depending on whole brain/ROI choice\n",
    "  track_dir = os.path.join(fmri_dir, track)\n",
    "\n",
    "  # get the selected subject's directory\n",
    "  sub_fmri_dir = os.path.join(track_dir, sub)\n",
    "\n",
    "  #result directory to store nifti file\n",
    "  results_dir = '/content/'\n",
    "\n",
    "  # mapping the data to voxels and storing in a nifti file\n",
    "  fmri_train_all,voxel_mask = get_fmri(sub_fmri_dir,\"WB\")\n",
    "  visual_mask_3D = np.zeros((78,93,71))\n",
    "  visual_mask_3D[voxel_mask==1]= fmri_train_all[vid_id,:]\n",
    "  brain_mask = './example.nii'\n",
    "  nii_save_path =  os.path.join(results_dir, 'vid_activity.nii')\n",
    "  saveasnii(brain_mask,nii_save_path,visual_mask_3D)\n",
    "\n",
    "  # visualizing saved nifti file\n",
    "  plotting.plot_glass_brain(nii_save_path,\n",
    "                          title='fMRI response',plot_abs=False,\n",
    "                          display_mode='lyr',colorbar=True)\n",
    "\n",
    "\n",
    "def get_fmri(fmri_dir, ROI):\n",
    "  \"\"\"This function loads fMRI data into a numpy array for to a given ROI.\n",
    "  Parameters\n",
    "  ----------\n",
    "  fmri_dir : str\n",
    "    path to fMRI data.\n",
    "  ROI : str\n",
    "    name of ROI.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  np.array\n",
    "    matrix of dimensions #train_vids x #repetitions x #voxels\n",
    "    containing fMRI responses to train videos of a given ROI\n",
    "  \"\"\"\n",
    "\n",
    "  # Loading ROI data\n",
    "  ROI_file = os.path.join(fmri_dir, ROI + \".pkl\")\n",
    "  ROI_data = load_dict(ROI_file)\n",
    "  # averaging ROI data across repetitions\n",
    "  ROI_data_train = np.mean(ROI_data[\"train\"], axis=1)\n",
    "  if ROI == \"WB\":\n",
    "    voxel_mask = ROI_data['voxel_mask']\n",
    "\n",
    "    return ROI_data_train, voxel_mask\n",
    "\n",
    "  return ROI_data_train\n",
    "\n",
    "def saveasnii(brain_mask,nii_save_path,nii_data):\n",
    "  img = nib.load(brain_mask)\n",
    "  nii_img = nib.Nifti1Image(nii_data, img.affine, img.header)\n",
    "  nib.save(nii_img, nii_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decord import VideoReader\n",
    "from decord import cpu, gpu\n",
    "from tqdm import tqdm\n",
    "from random import randrange\n",
    "\n",
    "def load_videos(path_to_videos, sample_strategy='standard', frame_n=3, win_n=3):\n",
    "    vid_list = os.listdir(path_to_videos)\n",
    "    vid_list.sort()\n",
    "    mp4_filename_format = \"{path}/{filename}\"\n",
    "    mp4_path_files = glob.glob(path_to_videos + '*.mp4')\n",
    "    X = {}\n",
    "    vr_sample = VideoReader(mp4_path_files[0], ctx=cpu(0))\n",
    "    i = 0\n",
    "\n",
    "    with tqdm(total = len(vid_list), position = 0, leave = True) as pbar:\n",
    "        for video in tqdm(vid_list, position = 0, leave = True):\n",
    "            mp4_filename = mp4_filename_format.format(path=path_to_videos, \n",
    "                                                filename=video)\n",
    "            vr = VideoReader(mp4_filename, ctx=cpu(0))\n",
    "      \n",
    "            if sample_strategy=='standard':\n",
    "                num_frames = len(vr)\n",
    "                X[i] = vr.get_batch([0, int(num_frames*0.5), num_frames-1]).asnumpy()\n",
    "            elif sample_strategy=='random':\n",
    "                sample_n = np.zeros((frame_n))\n",
    "                for x in range(sample_n.shape[0]):\n",
    "                    sample_n[x] = randrange(0, len(vr))\n",
    "                sample_n = sample_n.astype(int)\n",
    "                X[i] = vr.get_batch([sample_n]).asnumpy()\n",
    "            elif sample_strategy=='average':\n",
    "                chunks = []\n",
    "                start=0\n",
    "                X[i]={}\n",
    "                for chunk in range(win_n):\n",
    "                    chunks.append(list(range(start, int(start + int(len(vr)/(win_n))))))\n",
    "                    tmp_chunk = np.mean(vr.get_batch([chunks[chunk]]).asnumpy(), axis=0)\n",
    "                    start =+  chunks[chunk][-1] + 1\n",
    "                    X[i][chunk] = np.mean(vr.get_batch([chunks[chunk]]).asnumpy(), axis=0).astype(int)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "return X\n",
    "\n",
    "\n",
    "#X = load_videos('/content/AlgonautsVideos268_All_30fpsmax/', sample_strategy='random', frame_n=4)\n",
    "X = load_videos('/content/AlgonautsVideos268_All_30fpsmax/', sample_strategy='average', win_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video2plot = 1\n",
    "frame2plot = 2\n",
    "imshow(X[video2plot][frame2plot])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "load_videos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
