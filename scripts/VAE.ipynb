{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VAE",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b0fc935f5caf486aafec9289828f0342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_24d2f4ec50ef4091a5ca222a61c1ce48",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75beb26e5a90448884c99b52c13e403e",
              "IPY_MODEL_db2e31b42ee84fc68b70c48dd1804412",
              "IPY_MODEL_5b4ff4a735d74741a16c28631eeb0e89"
            ]
          }
        },
        "24d2f4ec50ef4091a5ca222a61c1ce48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75beb26e5a90448884c99b52c13e403e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36e95b8e5c0f4fc49eebe988cdc69657",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epochs:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23681221c03c41eeb621a56f7b7ef037"
          }
        },
        "db2e31b42ee84fc68b70c48dd1804412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_45110124517b4a849eecb54ba214483b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5e38eac46734a63a4b8bbc1e232e2dd"
          }
        },
        "5b4ff4a735d74741a16c28631eeb0e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a789ff430c704c88b424e3c703837826",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0b7665c14274ce5820be74acc04b48c"
          }
        },
        "36e95b8e5c0f4fc49eebe988cdc69657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23681221c03c41eeb621a56f7b7ef037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45110124517b4a849eecb54ba214483b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5e38eac46734a63a4b8bbc1e232e2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a789ff430c704c88b424e3c703837826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0b7665c14274ce5820be74acc04b48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3e5444497f04c3fb0448a2c9beca7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_20b12c4866024855b96441d9af95158b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c8f9ce945f142a4b6c73bbf47331bcc",
              "IPY_MODEL_ce6482f2519f41a5897da75db74951cf",
              "IPY_MODEL_93ec85a8904f4624a68cabc1f6f4c7ad"
            ]
          }
        },
        "20b12c4866024855b96441d9af95158b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c8f9ce945f142a4b6c73bbf47331bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d03ad9486fae4c4b8710f8f72406fc6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Batches:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61f7542ccddb437786f81f8e2eaf64df"
          }
        },
        "ce6482f2519f41a5897da75db74951cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b60b63f8845d40b983df3bbecda64574",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 3125,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05251c6ee2824476825857669474bbd9"
          }
        },
        "93ec85a8904f4624a68cabc1f6f4c7ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_859e4ea521ab43f6b114cc85c92ce364",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/3125 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d44fa98329b9437f81289703de125680"
          }
        },
        "d03ad9486fae4c4b8710f8f72406fc6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61f7542ccddb437786f81f8e2eaf64df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b60b63f8845d40b983df3bbecda64574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05251c6ee2824476825857669474bbd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "859e4ea521ab43f6b114cc85c92ce364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d44fa98329b9437f81289703de125680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdB66FX2dUq2"
      },
      "source": [
        "<a   href=\"https://colab.research.google.com/github/eduardojdiniz/Buzznauts/blob/master/scripts/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imi5aU8c7a6x",
        "outputId": "aca239a0-50da-418a-cbb5-4ce94178a4c1"
      },
      "source": [
        "!pip install duecredit --quiet\n",
        "!git clone https://github.com/eduardojdiniz/Buzznauts --quiet\n",
        "!pip install torchinfo --quiet\n",
        "!pip install wandb --quiet"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Buzznauts' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "lWeP5YOo3dTB",
        "outputId": "9b9342ce-8a92-4b3b-b1c3-18763b5b41c6"
      },
      "source": [
        "# install pytorch (http://pytorch.org/) if run from Google Colaboratory\n",
        "# Imports\n",
        "import torch\n",
        "import random\n",
        "import nltk\n",
        "import pickle\n",
        "import wandb\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os.path as op\n",
        "\n",
        "# Initialize instance of W&B\n",
        "wandb.init()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2gfc49oa) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2gfc49oa). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.0<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">peach-deluge-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/rwoodry/uncategorized\" target=\"_blank\">https://wandb.ai/rwoodry/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/rwoodry/uncategorized/runs/16utoq90\" target=\"_blank\">https://wandb.ai/rwoodry/uncategorized/runs/16utoq90</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210817_165133-16utoq90</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fe2924fba90>"
            ],
            "text/html": [
              "<h1>Run(16utoq90)</h1><iframe src=\"https://wandb.ai/rwoodry/uncategorized/runs/16utoq90\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL557EF0scbI",
        "outputId": "ab7e768c-4e8f-49c0-e1e3-5de5d077be30"
      },
      "source": [
        "# @title Download MNIST and CIFAR10 datasets\n",
        "import tarfile, requests, os\n",
        "\n",
        "fname = 'MNIST.tar.gz'\n",
        "name = 'mnist'\n",
        "url = 'https://osf.io/y2fj6/download'\n",
        "\n",
        "if not os.path.exists(name):\n",
        "  print('\\nDownloading MNIST dataset...')\n",
        "  r = requests.get(url, allow_redirects=True)\n",
        "  with open(fname, 'wb') as fh:\n",
        "    fh.write(r.content)\n",
        "  print('\\nDownloading MNIST completed..\\n')\n",
        "\n",
        "if not os.path.exists(name):\n",
        "  with tarfile.open(fname) as tar:\n",
        "    tar.extractall(name)\n",
        "    os.remove(fname)\n",
        "else:\n",
        "  print('MNIST dataset has been dowloaded.\\n')\n",
        "\n",
        "\n",
        "fname = 'cifar-10-python.tar.gz'\n",
        "name = 'cifar10'\n",
        "url = 'https://osf.io/jbpme/download'\n",
        "\n",
        "if not os.path.exists(name):\n",
        "  print('\\nDownloading CIFAR10 dataset...')\n",
        "  r = requests.get(url, allow_redirects=True)\n",
        "  with open(fname, 'wb') as fh:\n",
        "    fh.write(r.content)\n",
        "  print('\\nDownloading CIFAR10 completed.')\n",
        "\n",
        "if not os.path.exists(name):\n",
        "  with tarfile.open(fname) as tar:\n",
        "    tar.extractall(name)\n",
        "    os.remove(fname)\n",
        "else:\n",
        "  print('CIFAR10 dataset has been dowloaded.')\n",
        "  \n",
        "\n",
        "# @markdown Load MNIST and CIFAR10 image datasets\n",
        "# See https://pytorch.org/docs/stable/torchvision/datasets.html\n",
        "\n",
        "# MNIST\n",
        "mnist = datasets.MNIST('./mnist/',\n",
        "                       train=True,\n",
        "                       transform=transforms.ToTensor(),\n",
        "                       download=False)\n",
        "mnist_val = datasets.MNIST('./mnist/',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor(),\n",
        "                           download=False)\n",
        "\n",
        "# CIFAR 10\n",
        "cifar10 = datasets.CIFAR10('./cifar10/',\n",
        "                           train=True,\n",
        "                           transform=transforms.ToTensor(),\n",
        "                           download=False)\n",
        "cifar10_val = datasets.CIFAR10('./cifar10/',\n",
        "                               train=False,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=False)\n",
        "\n",
        "def get_data(name='mnist'):\n",
        "  if name == 'mnist':\n",
        "    my_dataset_name = \"MNIST\"\n",
        "    my_dataset = mnist\n",
        "    my_valset = mnist_val\n",
        "    my_dataset_shape = (1, 28, 28)\n",
        "    my_dataset_size = 28 * 28\n",
        "  elif name == 'cifar10':\n",
        "    my_dataset_name = \"CIFAR10\"\n",
        "    my_dataset = cifar10\n",
        "    my_valset = cifar10_val\n",
        "    my_dataset_shape = (3, 32, 32)\n",
        "    my_dataset_size = 3 * 32 * 32\n",
        "\n",
        "  return my_dataset, my_dataset_name, my_dataset_shape, my_dataset_size, my_valset\n",
        "\n",
        "\n",
        "train_set, dataset_name, data_shape, data_size, valid_set = get_data(name='cifar10')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST dataset has been dowloaded.\n",
            "\n",
            "CIFAR10 dataset has been dowloaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqJGvpAf3zhJ"
      },
      "source": [
        "class BiasLayer(nn.Module):\n",
        "  def __init__(self, shape):\n",
        "    super(BiasLayer, self).__init__()\n",
        "    init_bias = torch.zeros(shape)\n",
        "    self.bias = nn.Parameter(init_bias, requires_grad=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x + self.bias\n",
        "\n",
        "\n",
        "def cout(x, layer):\n",
        "  \"\"\"Unnecessarily complicated but complete way to\n",
        "  calculate the output depth, height and width size for a Conv2D layer\n",
        "\n",
        "  Args:\n",
        "    x (tuple): input size (depth, height, width)\n",
        "    layer (nn.Conv2d): the Conv2D layer\n",
        "\n",
        "  returns:\n",
        "    (int): output shape as given in [Ref]\n",
        "\n",
        "  Ref:\n",
        "    https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "  \"\"\"\n",
        "  assert isinstance(layer, nn.Conv2d)\n",
        "  p = layer.padding if isinstance(layer.padding, tuple) else (layer.padding,)\n",
        "  k = layer.kernel_size if isinstance(layer.kernel_size, tuple) else (layer.kernel_size,)\n",
        "  d = layer.dilation if isinstance(layer.dilation, tuple) else (layer.dilation,)\n",
        "  s = layer.stride if isinstance(layer.stride, tuple) else (layer.stride,)\n",
        "  in_depth, in_height, in_width = x\n",
        "  out_depth = layer.out_channels\n",
        "  out_height = 1 + (in_height + 2 * p[0] - (k[0] - 1) * d[0] - 1) // s[0]\n",
        "  out_width = 1 + (in_width + 2 * p[-1] - (k[-1] - 1) * d[-1] - 1) // s[-1]\n",
        "  return (out_depth, out_height, out_width)\n",
        "\n",
        "\n",
        "# @title Helper functions\n",
        "\n",
        "#@title Helper functions\n",
        "\n",
        "def image_moments(image_batches, n_batches=None):\n",
        "  \"\"\"\n",
        "  Compute mean an covariance of all pixels from batches of images\n",
        "  \"\"\"\n",
        "  m1, m2 = torch.zeros((), device=DEVICE), torch.zeros((), device=DEVICE)\n",
        "  n = 0\n",
        "  for im in tqdm(image_batches, total=n_batches, leave=False,\n",
        "                 desc='Computing pixel mean and covariance...'):\n",
        "    im = im.to(DEVICE)\n",
        "    b = im.size()[0]\n",
        "    im = im.view(b, -1)\n",
        "    m1 = m1 + im.sum(dim=0)\n",
        "    m2 = m2 + (im.view(b,-1,1) * im.view(b,1,-1)).sum(dim=0)\n",
        "    n += b\n",
        "  m1, m2 = m1/n, m2/n\n",
        "  cov = m2 - m1.view(-1,1)*m1.view(1,-1)\n",
        "  return m1.cpu(), cov.cpu()\n",
        "\n",
        "\n",
        "def interpolate(A, B, num_interps):\n",
        "  if A.shape != B.shape:\n",
        "    raise ValueError('A and B must have the same shape to interpolate.')\n",
        "  alphas = np.linspace(0, 1, num_interps)\n",
        "  return np.array([(1-a)*A + a*B for a in alphas])\n",
        "\n",
        "\n",
        "def kl_q_p(zs, phi):\n",
        "  \"\"\"Given [b,n,k] samples of z drawn from q, compute estimate of KL(q||p).\n",
        "  phi must be size [b,k+1]\n",
        "\n",
        "  This uses mu_p = 0 and sigma_p = 1, which simplifies the log(p(zs)) term to\n",
        "  just -1/2*(zs**2)\n",
        "  \"\"\"\n",
        "  b, n, k = zs.size()\n",
        "  mu_q, log_sig_q = phi[:,:-1], phi[:,-1]\n",
        "  log_p = -0.5*(zs**2)\n",
        "  log_q = -0.5*(zs - mu_q.view(b,1,k))**2 / log_sig_q.exp().view(b,1,1)**2 - log_sig_q.view(b,1,-1)\n",
        "  # Size of log_q and log_p is [b,n,k]. Sum along [k] but mean along [b,n]\n",
        "  return (log_q - log_p).sum(dim=2).mean(dim=(0,1))\n",
        "\n",
        "\n",
        "def log_p_x(x, mu_xs, sig_x):\n",
        "  \"\"\"Given [batch, ...] input x and [batch, n, ...] reconstructions, compute\n",
        "  pixel-wise log Gaussian probability\n",
        "\n",
        "  Sum over pixel dimensions, but mean over batch and samples.\n",
        "  \"\"\"\n",
        "  b, n = mu_xs.size()[:2]\n",
        "  # Flatten out pixels and add a singleton dimension [1] so that x will be\n",
        "  # implicitly expanded when combined with mu_xs\n",
        "  x = x.reshape(b, 1, -1)\n",
        "  _, _, p = x.size()\n",
        "  squared_error = (x - mu_xs.view(b, n, -1))**2 / (2*sig_x**2)\n",
        "\n",
        "  # Size of squared_error is [b,n,p]. log prob is by definition sum over [p].\n",
        "  # Expected value requires mean over [n]. Handling different size batches\n",
        "  # requires mean over [b].\n",
        "  return -(squared_error + torch.log(sig_x)).sum(dim=2).mean(dim=(0,1))\n",
        "\n",
        "\n",
        "def pca_encoder_decoder(mu, cov, k):\n",
        "  \"\"\"\n",
        "  Compute encoder and decoder matrices for PCA dimensionality reduction\n",
        "  \"\"\"\n",
        "  mu = mu.view(1,-1)\n",
        "  u, s, v = torch.svd_lowrank(cov, q=k)\n",
        "  W_encode = v / torch.sqrt(s)\n",
        "  W_decode = u * torch.sqrt(s)\n",
        "\n",
        "  def pca_encode(x):\n",
        "    # Encoder: subtract mean image and project onto top K eigenvectors of\n",
        "    # the data covariance\n",
        "    return (x.view(-1,mu.numel()) - mu) @ W_encode\n",
        "\n",
        "  def pca_decode(h):\n",
        "    # Decoder: un-project then add back in the mean\n",
        "    return (h @ W_decode.T) + mu\n",
        "\n",
        "  return pca_encode, pca_decode\n",
        "\n",
        "\n",
        "def cout(x, layer):\n",
        "  \"\"\"Unnecessarily complicated but complete way to\n",
        "  calculate the output depth, height and width size for a Conv2D layer\n",
        "\n",
        "  Args:\n",
        "    x (tuple): input size (depth, height, width)\n",
        "    layer (nn.Conv2d): the Conv2D layer\n",
        "\n",
        "  returns:\n",
        "    (int): output shape as given in [Ref]\n",
        "\n",
        "  Ref:\n",
        "    https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "  \"\"\"\n",
        "  assert isinstance(layer, nn.Conv2d)\n",
        "  p = layer.padding if isinstance(layer.padding, tuple) else (layer.padding,)\n",
        "  k = layer.kernel_size if isinstance(layer.kernel_size, tuple) else (layer.kernel_size,)\n",
        "  d = layer.dilation if isinstance(layer.dilation, tuple) else (layer.dilation,)\n",
        "  s = layer.stride if isinstance(layer.stride, tuple) else (layer.stride,)\n",
        "  in_depth, in_height, in_width = x\n",
        "  out_depth = layer.out_channels\n",
        "  out_height = 1 + (in_height + 2 * p[0] - (k[0] - 1) * d[0] - 1) // s[0]\n",
        "  out_width = 1 + (in_width + 2 * p[-1] - (k[-1] - 1) * d[-1] - 1) // s[-1]\n",
        "  return (out_depth, out_height, out_width)\n",
        "\n",
        "\n",
        "def load_vaegan_weights(model, pretrained_path):\n",
        "  # load pretrained weights\n",
        "  pretrained_fn = open(pretrained_path,'rb')\n",
        "  pretrained = pickle.load(pretrained_fn)\n",
        "\n",
        "  # have a look what's in the pretrained file\n",
        "  old_keynames=[]\n",
        "  for key, value in pretrained.items() :\n",
        "    print (key,value.shape) \n",
        "    old_keynames.append(key) \n",
        "\n",
        "  # get the keynames of our model\n",
        "  curr_state=model.state_dict()\n",
        "  new_keynames=[]\n",
        "  for key, value in curr_state.items() :\n",
        "      if key.startswith('q_conv'):\n",
        "        new_keynames.append(key)\n",
        "\n",
        "  # change the names of the pretrained model to match our model\n",
        "  for i in range(len(old_keynames)):\n",
        "    pretrained[new_keynames[i]] = pretrained[old_keynames[i]]\n",
        "    del pretrained[old_keynames[i]]\n",
        "\n",
        "  # change size & make the weights a torch\n",
        "  # In TF, Conv2d filter shape is [filter_height, filter_width, in_channels, out_channels],\n",
        "  # while in Pytorch is (out_channels, in_channels, kernel_size[0], kernel_size[1])\n",
        "  # SO we need to permute [3,2,0,1]\n",
        "  for key, value in pretrained.items() :\n",
        "    if len(value.shape)==4:\n",
        "      new_val=torch.tensor(value)\n",
        "      new_val=new_val.permute(3,2,0,1)\n",
        "    else: \n",
        "      new_val=torch.tensor(value)\n",
        "    \n",
        "    pretrained[key] = new_val\n",
        "\n",
        "  return pretrained"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWoN9EZf9j9Q"
      },
      "source": [
        "Convolutional Auto Encoder [FULL]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F929qabx7PXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f5046a-77ac-433b-e7d9-7431145cb224"
      },
      "source": [
        "K_VAE = 1024\n",
        "\n",
        "class ConvVarAutoEncoder(nn.Module):\n",
        "  def __init__(self, K, num_filters=[192, 256, 384, 512, 768], filter_size=3):\n",
        "    super(ConvVarAutoEncoder, self).__init__()\n",
        "    ## 5 Conv Layers\n",
        "    filter_reduction = 5 * (filter_size // 2)\n",
        "\n",
        "    self.shape_after_conv = calc_output_size(data_shape, filter_size, num_filters)\n",
        "    \n",
        "    self.flat_shape = self.shape_after_conv[0] * self.shape_after_conv[1] * self.shape_after_conv[2]\n",
        "    \n",
        "    # Double for each additional layer of Conv\n",
        "    flat_size_after_conv = self.shape_after_conv[0] * self.shape_after_conv[1] * self.shape_after_conv[2]\n",
        "\n",
        "    # ENCODER\n",
        "    self.q_bias = BiasLayer(data_shape)\n",
        "    self.q_conv_1 = nn.Conv2d(data_shape[0], num_filters[0], filter_size)\n",
        "    self.q_conv_2 = nn.Conv2d(num_filters[0], num_filters[1], filter_size)\n",
        "    self.q_conv_3 = nn.Conv2d(num_filters[1], num_filters[2], filter_size)\n",
        "    self.q_conv_4 = nn.Conv2d(num_filters[2], num_filters[3], filter_size)\n",
        "    self.q_conv_5 = nn.Conv2d(num_filters[3], num_filters[4], filter_size)\n",
        "    self.q_flatten = nn.Flatten()\n",
        "    self.q_fc_phi = nn.Linear(self.flat_shape, K+1)\n",
        "\n",
        "    # DECODER\n",
        "    self.p_fc_upsample = nn.Linear(K, self.flat_shape)\n",
        "    self.p_unflatten = nn.Unflatten(-1, self.shape_after_conv)\n",
        "    self.p_deconv_1 = nn.ConvTranspose2d(num_filters[4], num_filters[3], filter_size)\n",
        "    self.p_deconv_2 = nn.ConvTranspose2d(num_filters[3], num_filters[2], filter_size)\n",
        "    self.p_deconv_3 = nn.ConvTranspose2d(num_filters[2], num_filters[1], filter_size)\n",
        "    self.p_deconv_4 = nn.ConvTranspose2d(num_filters[1], num_filters[0], filter_size)\n",
        "    self.p_deconv_5 = nn.ConvTranspose2d(num_filters[0], data_shape[0], filter_size)\n",
        "\n",
        "    self.p_bias = BiasLayer(data_shape)\n",
        "\n",
        "    # Define a special extra parameter to learn scalar sig_x for all pixels\n",
        "    self.log_sig_x = nn.Parameter(torch.zeros(()))\n",
        "\n",
        "\n",
        "  def infer(self, x):\n",
        "    \"\"\"Map (batch of) x to (batch of) phi which can then be passed to\n",
        "    rsample to get z\n",
        "    \"\"\"\n",
        "    s = self.q_bias(x)\n",
        "    s = F.elu(self.q_conv_1(s))\n",
        "    s = F.elu(self.q_conv_2(s))\n",
        "    s = F.elu(self.q_conv_3(s))\n",
        "    s = F.elu(self.q_conv_4(s))\n",
        "    s = F.elu(self.q_conv_5(s))\n",
        "    flat_s = s.view(s.size()[0], -1)\n",
        "    phi = self.q_fc_phi(flat_s)\n",
        "    return phi\n",
        "\n",
        "\n",
        "  def generate(self, zs):\n",
        "    \"\"\"Map [b,n,k] sized samples of z to [b,n,p] sized images\n",
        "    \"\"\"\n",
        "    # Note that for the purposes of passing through the generator, we need\n",
        "    # to reshape zs to be size [b*n,k]\n",
        "    b, n, k = zs.size()\n",
        "    s = zs.view(b*n, -1)\n",
        "    s = F.elu(self.p_fc_upsample(s)).view((b*n,) + self.shape_after_conv)\n",
        "    s = F.elu(self.p_deconv_1(s))\n",
        "    s = F.elu(self.p_deconv_2(s))\n",
        "    s = F.elu(self.p_deconv_3(s))\n",
        "    s = F.elu(self.p_deconv_4(s))\n",
        "    s = self.p_deconv_5(s)\n",
        "    s = self.p_bias(s)\n",
        "    mu_xs = s.view(b, n, -1)\n",
        "    return mu_xs\n",
        "\n",
        "\n",
        "  def decode(self, zs):\n",
        "    # Included for compatability with conv-AE code\n",
        "    return self.generate(zs.unsqueeze(0))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # VAE.forward() is not used for training, but we'll treat it like a\n",
        "    # classic autoencoder by taking a single sample of z ~ q\n",
        "    phi = self.infer(x)\n",
        "    zs = rsample(phi, 1)\n",
        "    return self.generate(zs).view(x.size())\n",
        "\n",
        "\n",
        "  def elbo(self, x, n=1):\n",
        "    \"\"\"Run input end to end through the VAE and compute the ELBO using n\n",
        "    samples of z\n",
        "    \"\"\"\n",
        "    phi = self.infer(x)\n",
        "    zs = rsample(phi, n)\n",
        "    mu_xs = self.generate(zs)\n",
        "    return log_p_x(x, mu_xs, self.log_sig_x.exp()) - kl_q_p(zs, phi)\n",
        "\n",
        "  \n",
        "  def load_my_state_dict(self, state_dict):\n",
        "    curr_state=self.state_dict()\n",
        "    \n",
        "    for name, param in state_dict.items():\n",
        "      print(type(param))\n",
        "      if name not in curr_state:\n",
        "        print('name does not exist -- skipping')\n",
        "        continue\n",
        "      if isinstance(param, torch.Tensor):\n",
        "          param = param.data\n",
        "      curr_state[name].copy_(param)\n",
        "\n",
        "\n",
        "###============================FUNCTIONS=========================###\n",
        "\n",
        "\n",
        "def expected_z(phi):\n",
        "  return phi[:, :-1]\n",
        "\n",
        "\n",
        "def rsample(phi, n_samples):\n",
        "  \"\"\"Sample z ~ q(z;phi)\n",
        "  Ouput z is size [b,n_samples,K] given phi with shape [b,K+1]. The first K\n",
        "  entries of each row of phi are the mean of q, and phi[:,-1] is the log\n",
        "  standard deviation\n",
        "  \"\"\"\n",
        "  b, kplus1 = phi.size()\n",
        "  k = kplus1-1\n",
        "  mu, sig = phi[:, :-1], phi[:,-1].exp()\n",
        "  eps = torch.randn(b, n_samples, k, device=phi.device)\n",
        "  return eps*sig.view(b,1,1) + mu.view(b,1,k)\n",
        "\n",
        "\n",
        "def train_vae(vae, dataset, epochs=10, n_samples=1000, freeze_idx = []):\n",
        "\n",
        "  for idx, param in enumerate(vae.parameters()): \n",
        "    if idx in freeze_idx: param.requires_grad = False\n",
        "\n",
        "  print(\"===Freezing layers:===\")\n",
        "\n",
        "  for name, param in vae.named_parameters(): \n",
        "    if param.requires_grad == False: print(\"\\t\" + name)\n",
        "\n",
        "  \n",
        "\n",
        "  # passing only those parameters that explicitly requires grad\n",
        "  opt = torch.optim.Adam(filter(lambda p: p.requires_grad, vae.parameters()), lr=1e-3, weight_decay=0)\n",
        "  elbo_vals = []\n",
        "  vae.to(DEVICE)\n",
        "  vae.train()\n",
        "  loader = DataLoader(dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
        "  for epoch in trange(epochs, desc='Epochs'):\n",
        "    for im, _ in tqdm(loader, total=len(dataset) // 16, desc='Batches', leave=False):\n",
        "      im = im.to(DEVICE)\n",
        "      opt.zero_grad()\n",
        "      loss = -vae.elbo(im)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "      elbo_vals.append(-loss.item())\n",
        "    \n",
        "      # W&B Logging at the end of each epoch\n",
        "      print(loss)\n",
        "      wandb.log(loss)\n",
        "\n",
        "  vae.to('cuda')\n",
        "  vae.eval()\n",
        "  return elbo_vals\n",
        "\n",
        "def calc_output_size(input_size, kernel_size, kchannels, padding=0, stride=1):\n",
        "  output_size = input_size\n",
        "  for kc in kchannels:\n",
        "    output_height = (output_size[1] + padding + padding - kernel_size) / (stride) + 1\n",
        "    output_width = (output_size[2] + padding + padding - kernel_size) / (stride) + 1\n",
        "\n",
        "    output_size = [kc, int(output_height), int(output_width)]\n",
        "    print(output_size)\n",
        "\n",
        "  return tuple(output_size)\n",
        "\n",
        "                     \n",
        "\n",
        "\n",
        "\n",
        "convVAE = ConvVarAutoEncoder(K=K_VAE)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[192, 30, 30]\n",
            "[256, 28, 28]\n",
            "[384, 26, 26]\n",
            "[512, 24, 24]\n",
            "[768, 22, 22]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7xotQyjkA_6",
        "outputId": "6bb94051-040e-4310-ce4e-1265d9b2f1a2"
      },
      "source": [
        "pretrained_path = '/content/drive/MyDrive/Buzznauts/data/pretrained/vaegan_enc_weights.pickle'\n",
        "pretrained = load_vaegan_weights(convVAE, pretrained_path)\n",
        "convVAE.load_my_state_dict(pretrained)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder/layer1/conv2d/W (3, 3, 3, 192)\n",
            "encoder/layer1/conv2d/b (192,)\n",
            "encoder/layer2/conv2d/W (3, 3, 192, 256)\n",
            "encoder/layer2/conv2d/b (256,)\n",
            "encoder/layer3/conv2d/W (3, 3, 256, 384)\n",
            "encoder/layer3/conv2d/b (384,)\n",
            "encoder/layer4/conv2d/W (3, 3, 384, 512)\n",
            "encoder/layer4/conv2d/b (512,)\n",
            "encoder/layer5/conv2d/W (3, 3, 512, 768)\n",
            "encoder/layer5/conv2d/b (768,)\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac8t_FT48Und",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "b0fc935f5caf486aafec9289828f0342",
            "24d2f4ec50ef4091a5ca222a61c1ce48",
            "75beb26e5a90448884c99b52c13e403e",
            "db2e31b42ee84fc68b70c48dd1804412",
            "5b4ff4a735d74741a16c28631eeb0e89",
            "36e95b8e5c0f4fc49eebe988cdc69657",
            "23681221c03c41eeb621a56f7b7ef037",
            "45110124517b4a849eecb54ba214483b",
            "f5e38eac46734a63a4b8bbc1e232e2dd",
            "a789ff430c704c88b424e3c703837826",
            "d0b7665c14274ce5820be74acc04b48c",
            "f3e5444497f04c3fb0448a2c9beca7c0",
            "20b12c4866024855b96441d9af95158b",
            "9c8f9ce945f142a4b6c73bbf47331bcc",
            "ce6482f2519f41a5897da75db74951cf",
            "93ec85a8904f4624a68cabc1f6f4c7ad",
            "d03ad9486fae4c4b8710f8f72406fc6a",
            "61f7542ccddb437786f81f8e2eaf64df",
            "b60b63f8845d40b983df3bbecda64574",
            "05251c6ee2824476825857669474bbd9",
            "859e4ea521ab43f6b114cc85c92ce364",
            "d44fa98329b9437f81289703de125680"
          ]
        },
        "outputId": "e81b75af-29dd-40e0-b56a-2813ba4064b9"
      },
      "source": [
        "DEVICE = 'cpu'\n",
        "\n",
        "wandb.watch(convVAE)\n",
        "trained_CVAE = train_vae(convVAE, train_set, epochs = 1, n_samples = 10, freeze_idx = [2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===Freezing layers:===\n",
            "\tq_conv_1.weight\n",
            "\tq_conv_1.bias\n",
            "\tq_conv_2.weight\n",
            "\tq_conv_2.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0fc935f5caf486aafec9289828f0342",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3e5444497f04c3fb0448a2c9beca7c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Batches:   0%|          | 0/3125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDmSS_f6hgot"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}