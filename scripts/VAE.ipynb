{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f68cbd1d45854729936ed5e6ac03cc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c1692888d06484a8d2bcc31db7f7d3a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_89b4c3ea57704a7f8cb192ce39959b8e",
              "IPY_MODEL_0b2b3afa04cf47498fccf6837f459c4a"
            ]
          }
        },
        "4c1692888d06484a8d2bcc31db7f7d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89b4c3ea57704a7f8cb192ce39959b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8b8ffab1c2ab47b6bcef783ffe691f41",
            "_dom_classes": [],
            "description": "Epochs:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c4dbba2a81a4e158e505f180e0f9ff3"
          }
        },
        "0b2b3afa04cf47498fccf6837f459c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47d187c6726648c4b114bfe898c29bb3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23834eaa2e7f40c38136cad6ee78654a"
          }
        },
        "8b8ffab1c2ab47b6bcef783ffe691f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c4dbba2a81a4e158e505f180e0f9ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47d187c6726648c4b114bfe898c29bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23834eaa2e7f40c38136cad6ee78654a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e2bf9383ac64ebca4f89a7b830de90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec99a37035a84b86b2ed6dee96c8c91f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_509af7c0d85d44a18b55f8dfc8a289f4",
              "IPY_MODEL_db9e31e0fcb4427d92646199bba12387"
            ]
          }
        },
        "ec99a37035a84b86b2ed6dee96c8c91f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "509af7c0d85d44a18b55f8dfc8a289f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fef6ef0dc41045f9a9bb93ca1ef283c4",
            "_dom_classes": [],
            "description": "Batches:  35%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 937,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 324,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b0c61d1ec474c708cc92e83c4dbfe7d"
          }
        },
        "db9e31e0fcb4427d92646199bba12387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78aed0a1d6e2468d8f6fcb767e9817f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 324/937 [02:30&lt;04:48,  2.12it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e06e2ac8fac14154a29d229417c7d48a"
          }
        },
        "fef6ef0dc41045f9a9bb93ca1ef283c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b0c61d1ec474c708cc92e83c4dbfe7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78aed0a1d6e2468d8f6fcb767e9817f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e06e2ac8fac14154a29d229417c7d48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdB66FX2dUq2"
      },
      "source": [
        "<a   href=\"https://colab.research.google.com/github/eduardojdiniz/Buzznauts/blob/master/scripts/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imi5aU8c7a6x",
        "outputId": "b09e30f1-7f7c-4ea2-e27a-c13865c05683"
      },
      "source": [
        "!pip install duecredit --quiet\n",
        "!git clone https://github.com/eduardojdiniz/Buzznauts --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 20 kB 36.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 30 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 40 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 51 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 61 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 71 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 81 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 86 kB 3.3 MB/s \n",
            "\u001b[?25h\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 39.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20 kB 43.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30 kB 48.7 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40 kB 50.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51 kB 52.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61 kB 54.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71 kB 56.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 81 kB 58.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 92 kB 59.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102 kB 58.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112 kB 58.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 122 kB 58.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 133 kB 58.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 143 kB 58.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 153 kB 58.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 163 kB 58.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 174 kB 58.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 179 kB 58.1 MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWeP5YOo3dTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7545fd-7658-4777-d980-9e1ac47bb051"
      },
      "source": [
        "# install pytorch (http://pytorch.org/) if run from Google Colaboratory\n",
        "# Imports\n",
        "import torch\n",
        "import random\n",
        "import nltk\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os.path as op"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL557EF0scbI",
        "outputId": "faa411a7-7dfa-4c35-a78f-31a44416a138"
      },
      "source": [
        "# @title Download MNIST and CIFAR10 datasets\n",
        "import tarfile, requests, os\n",
        "\n",
        "fname = 'MNIST.tar.gz'\n",
        "name = 'mnist'\n",
        "url = 'https://osf.io/y2fj6/download'\n",
        "\n",
        "if not os.path.exists(name):\n",
        "  print('\\nDownloading MNIST dataset...')\n",
        "  r = requests.get(url, allow_redirects=True)\n",
        "  with open(fname, 'wb') as fh:\n",
        "    fh.write(r.content)\n",
        "  print('\\nDownloading MNIST completed..\\n')\n",
        "\n",
        "if not os.path.exists(name):\n",
        "  with tarfile.open(fname) as tar:\n",
        "    tar.extractall(name)\n",
        "    os.remove(fname)\n",
        "else:\n",
        "  print('MNIST dataset has been dowloaded.\\n')\n",
        "\n",
        "\n",
        "fname = 'cifar-10-python.tar.gz'\n",
        "name = 'cifar10'\n",
        "url = 'https://osf.io/jbpme/download'\n",
        "\n",
        "if not os.path.exists(name):\n",
        "  print('\\nDownloading CIFAR10 dataset...')\n",
        "  r = requests.get(url, allow_redirects=True)\n",
        "  with open(fname, 'wb') as fh:\n",
        "    fh.write(r.content)\n",
        "  print('\\nDownloading CIFAR10 completed.')\n",
        "\n",
        "if not os.path.exists(name):\n",
        "  with tarfile.open(fname) as tar:\n",
        "    tar.extractall(name)\n",
        "    os.remove(fname)\n",
        "else:\n",
        "  print('CIFAR10 dataset has been dowloaded.')\n",
        "  \n",
        "\n",
        "# @markdown Load MNIST and CIFAR10 image datasets\n",
        "# See https://pytorch.org/docs/stable/torchvision/datasets.html\n",
        "\n",
        "# MNIST\n",
        "mnist = datasets.MNIST('./mnist/',\n",
        "                       train=True,\n",
        "                       transform=transforms.ToTensor(),\n",
        "                       download=False)\n",
        "mnist_val = datasets.MNIST('./mnist/',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor(),\n",
        "                           download=False)\n",
        "\n",
        "# CIFAR 10\n",
        "cifar10 = datasets.CIFAR10('./cifar10/',\n",
        "                           train=True,\n",
        "                           transform=transforms.ToTensor(),\n",
        "                           download=False)\n",
        "cifar10_val = datasets.CIFAR10('./cifar10/',\n",
        "                               train=False,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=False)\n",
        "\n",
        "def get_data(name='mnist'):\n",
        "  if name == 'mnist':\n",
        "    my_dataset_name = \"MNIST\"\n",
        "    my_dataset = mnist\n",
        "    my_valset = mnist_val\n",
        "    my_dataset_shape = (1, 28, 28)\n",
        "    my_dataset_size = 28 * 28\n",
        "  elif name == 'cifar10':\n",
        "    my_dataset_name = \"CIFAR10\"\n",
        "    my_dataset = cifar10\n",
        "    my_valset = cifar10_val\n",
        "    my_dataset_shape = (3, 32, 32)\n",
        "    my_dataset_size = 3 * 32 * 32\n",
        "\n",
        "  return my_dataset, my_dataset_name, my_dataset_shape, my_dataset_size, my_valset\n",
        "\n",
        "\n",
        "train_set, dataset_name, data_shape, data_size, valid_set = get_data(name='mnist')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading MNIST dataset...\n",
            "\n",
            "Downloading MNIST completed..\n",
            "\n",
            "\n",
            "Downloading CIFAR10 dataset...\n",
            "\n",
            "Downloading CIFAR10 completed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqJGvpAf3zhJ"
      },
      "source": [
        "class BiasLayer(nn.Module):\n",
        "  def __init__(self, shape):\n",
        "    super(BiasLayer, self).__init__()\n",
        "    init_bias = torch.zeros(shape)\n",
        "    self.bias = nn.Parameter(init_bias, requires_grad=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x + self.bias\n",
        "\n",
        "\n",
        "def cout(x, layer):\n",
        "  \"\"\"Unnecessarily complicated but complete way to\n",
        "  calculate the output depth, height and width size for a Conv2D layer\n",
        "\n",
        "  Args:\n",
        "    x (tuple): input size (depth, height, width)\n",
        "    layer (nn.Conv2d): the Conv2D layer\n",
        "\n",
        "  returns:\n",
        "    (int): output shape as given in [Ref]\n",
        "\n",
        "  Ref:\n",
        "    https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "  \"\"\"\n",
        "  assert isinstance(layer, nn.Conv2d)\n",
        "  p = layer.padding if isinstance(layer.padding, tuple) else (layer.padding,)\n",
        "  k = layer.kernel_size if isinstance(layer.kernel_size, tuple) else (layer.kernel_size,)\n",
        "  d = layer.dilation if isinstance(layer.dilation, tuple) else (layer.dilation,)\n",
        "  s = layer.stride if isinstance(layer.stride, tuple) else (layer.stride,)\n",
        "  in_depth, in_height, in_width = x\n",
        "  out_depth = layer.out_channels\n",
        "  out_height = 1 + (in_height + 2 * p[0] - (k[0] - 1) * d[0] - 1) // s[0]\n",
        "  out_width = 1 + (in_width + 2 * p[-1] - (k[-1] - 1) * d[-1] - 1) // s[-1]\n",
        "  return (out_depth, out_height, out_width)\n",
        "\n",
        "\n",
        "# @title Helper functions\n",
        "\n",
        "#@title Helper functions\n",
        "\n",
        "def image_moments(image_batches, n_batches=None):\n",
        "  \"\"\"\n",
        "  Compute mean an covariance of all pixels from batches of images\n",
        "  \"\"\"\n",
        "  m1, m2 = torch.zeros((), device=DEVICE), torch.zeros((), device=DEVICE)\n",
        "  n = 0\n",
        "  for im in tqdm(image_batches, total=n_batches, leave=False,\n",
        "                 desc='Computing pixel mean and covariance...'):\n",
        "    im = im.to(DEVICE)\n",
        "    b = im.size()[0]\n",
        "    im = im.view(b, -1)\n",
        "    m1 = m1 + im.sum(dim=0)\n",
        "    m2 = m2 + (im.view(b,-1,1) * im.view(b,1,-1)).sum(dim=0)\n",
        "    n += b\n",
        "  m1, m2 = m1/n, m2/n\n",
        "  cov = m2 - m1.view(-1,1)*m1.view(1,-1)\n",
        "  return m1.cpu(), cov.cpu()\n",
        "\n",
        "\n",
        "def interpolate(A, B, num_interps):\n",
        "  if A.shape != B.shape:\n",
        "    raise ValueError('A and B must have the same shape to interpolate.')\n",
        "  alphas = np.linspace(0, 1, num_interps)\n",
        "  return np.array([(1-a)*A + a*B for a in alphas])\n",
        "\n",
        "\n",
        "def kl_q_p(zs, phi):\n",
        "  \"\"\"Given [b,n,k] samples of z drawn from q, compute estimate of KL(q||p).\n",
        "  phi must be size [b,k+1]\n",
        "\n",
        "  This uses mu_p = 0 and sigma_p = 1, which simplifies the log(p(zs)) term to\n",
        "  just -1/2*(zs**2)\n",
        "  \"\"\"\n",
        "  b, n, k = zs.size()\n",
        "  mu_q, log_sig_q = phi[:,:-1], phi[:,-1]\n",
        "  log_p = -0.5*(zs**2)\n",
        "  log_q = -0.5*(zs - mu_q.view(b,1,k))**2 / log_sig_q.exp().view(b,1,1)**2 - log_sig_q.view(b,1,-1)\n",
        "  # Size of log_q and log_p is [b,n,k]. Sum along [k] but mean along [b,n]\n",
        "  return (log_q - log_p).sum(dim=2).mean(dim=(0,1))\n",
        "\n",
        "\n",
        "def log_p_x(x, mu_xs, sig_x):\n",
        "  \"\"\"Given [batch, ...] input x and [batch, n, ...] reconstructions, compute\n",
        "  pixel-wise log Gaussian probability\n",
        "\n",
        "  Sum over pixel dimensions, but mean over batch and samples.\n",
        "  \"\"\"\n",
        "  b, n = mu_xs.size()[:2]\n",
        "  # Flatten out pixels and add a singleton dimension [1] so that x will be\n",
        "  # implicitly expanded when combined with mu_xs\n",
        "  x = x.reshape(b, 1, -1)\n",
        "  _, _, p = x.size()\n",
        "  squared_error = (x - mu_xs.view(b, n, -1))**2 / (2*sig_x**2)\n",
        "\n",
        "  # Size of squared_error is [b,n,p]. log prob is by definition sum over [p].\n",
        "  # Expected value requires mean over [n]. Handling different size batches\n",
        "  # requires mean over [b].\n",
        "  return -(squared_error + torch.log(sig_x)).sum(dim=2).mean(dim=(0,1))\n",
        "\n",
        "\n",
        "def pca_encoder_decoder(mu, cov, k):\n",
        "  \"\"\"\n",
        "  Compute encoder and decoder matrices for PCA dimensionality reduction\n",
        "  \"\"\"\n",
        "  mu = mu.view(1,-1)\n",
        "  u, s, v = torch.svd_lowrank(cov, q=k)\n",
        "  W_encode = v / torch.sqrt(s)\n",
        "  W_decode = u * torch.sqrt(s)\n",
        "\n",
        "  def pca_encode(x):\n",
        "    # Encoder: subtract mean image and project onto top K eigenvectors of\n",
        "    # the data covariance\n",
        "    return (x.view(-1,mu.numel()) - mu) @ W_encode\n",
        "\n",
        "  def pca_decode(h):\n",
        "    # Decoder: un-project then add back in the mean\n",
        "    return (h @ W_decode.T) + mu\n",
        "\n",
        "  return pca_encode, pca_decode\n",
        "\n",
        "\n",
        "def cout(x, layer):\n",
        "  \"\"\"Unnecessarily complicated but complete way to\n",
        "  calculate the output depth, height and width size for a Conv2D layer\n",
        "\n",
        "  Args:\n",
        "    x (tuple): input size (depth, height, width)\n",
        "    layer (nn.Conv2d): the Conv2D layer\n",
        "\n",
        "  returns:\n",
        "    (int): output shape as given in [Ref]\n",
        "\n",
        "  Ref:\n",
        "    https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "  \"\"\"\n",
        "  assert isinstance(layer, nn.Conv2d)\n",
        "  p = layer.padding if isinstance(layer.padding, tuple) else (layer.padding,)\n",
        "  k = layer.kernel_size if isinstance(layer.kernel_size, tuple) else (layer.kernel_size,)\n",
        "  d = layer.dilation if isinstance(layer.dilation, tuple) else (layer.dilation,)\n",
        "  s = layer.stride if isinstance(layer.stride, tuple) else (layer.stride,)\n",
        "  in_depth, in_height, in_width = x\n",
        "  out_depth = layer.out_channels\n",
        "  out_height = 1 + (in_height + 2 * p[0] - (k[0] - 1) * d[0] - 1) // s[0]\n",
        "  out_width = 1 + (in_width + 2 * p[-1] - (k[-1] - 1) * d[-1] - 1) // s[-1]\n",
        "  return (out_depth, out_height, out_width)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWoN9EZf9j9Q"
      },
      "source": [
        "Convolutional Auto Encoder [FULL]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F929qabx7PXM"
      },
      "source": [
        "K_VAE = 1024\n",
        "\n",
        "class ConvVarAutoEncoder(nn.Module):\n",
        "  def __init__(self, K, num_filters=[192, 256, 384, 512, 768], filter_size=3):\n",
        "    super(ConvVarAutoEncoder, self).__init__()\n",
        "    ## 5 Conv Layers\n",
        "    filter_reduction = 5 * (filter_size // 2)\n",
        "    self.fs = 0\n",
        "\n",
        "    self.shape_after_conv = (768,\n",
        "                             data_shape[1] - 2 * filter_reduction,\n",
        "                             data_shape[2] - 2 * filter_reduction)\n",
        "    \n",
        "    # Double for each additional layer of Conv\n",
        "    flat_size_after_conv = self.shape_after_conv[0] * self.shape_after_conv[1] * self.shape_after_conv[2]\n",
        "\n",
        "    # ENCODER\n",
        "    self.q_bias = BiasLayer(data_shape)\n",
        "    self.q_conv_1 = nn.Conv2d(data_shape[0], num_filters[0], filter_size)\n",
        "    self.q_conv_2 = nn.Conv2d(num_filters[0], num_filters[1], filter_size)\n",
        "    self.q_conv_3 = nn.Conv2d(num_filters[1], num_filters[2], filter_size)\n",
        "    self.q_conv_4 = nn.Conv2d(num_filters[2], num_filters[3], filter_size)\n",
        "    self.q_conv_5 = nn.Conv2d(num_filters[3], num_filters[4], filter_size)\n",
        "    self.q_flatten = nn.Flatten()\n",
        "    self.q_fc_phi = nn.Linear(248832, K+1)\n",
        "\n",
        "    # DECODER\n",
        "    self.p_fc_upsample = nn.Linear(K, 248832)\n",
        "    self.p_unflatten = nn.Unflatten(-1, self.shape_after_conv)\n",
        "    self.p_deconv_1 = nn.ConvTranspose2d(num_filters[4], num_filters[3], filter_size)\n",
        "    self.p_deconv_2 = nn.ConvTranspose2d(num_filters[3], num_filters[2], filter_size)\n",
        "    self.p_deconv_3 = nn.ConvTranspose2d(num_filters[2], num_filters[1], filter_size)\n",
        "    self.p_deconv_4 = nn.ConvTranspose2d(num_filters[1], num_filters[0], filter_size)\n",
        "    self.p_deconv_5 = nn.ConvTranspose2d(num_filters[0], data_shape[0], filter_size)\n",
        "\n",
        "    self.p_bias = BiasLayer(data_shape)\n",
        "\n",
        "    # Define a special extra parameter to learn scalar sig_x for all pixels\n",
        "    self.log_sig_x = nn.Parameter(torch.zeros(()))\n",
        "\n",
        "\n",
        "  def infer(self, x):\n",
        "    \"\"\"Map (batch of) x to (batch of) phi which can then be passed to\n",
        "    rsample to get z\n",
        "    \"\"\"\n",
        "    s = self.q_bias(x)\n",
        "    s = F.relu(self.q_conv_1(s))\n",
        "    s = F.relu(self.q_conv_2(s))\n",
        "    s = F.relu(self.q_conv_3(s))\n",
        "    s = F.relu(self.q_conv_4(s))\n",
        "    s = F.relu(self.q_conv_5(s))\n",
        "    flat_s = s.view(s.size()[0], -1)\n",
        "    phi = self.q_fc_phi(flat_s)\n",
        "    return phi\n",
        "\n",
        "\n",
        "  def generate(self, zs):\n",
        "    \"\"\"Map [b,n,k] sized samples of z to [b,n,p] sized images\n",
        "    \"\"\"\n",
        "    # Note that for the purposes of passing through the generator, we need\n",
        "    # to reshape zs to be size [b*n,k]\n",
        "    b, n, k = zs.size()\n",
        "    s = zs.view(b*n, -1)\n",
        "    s = F.relu(self.p_fc_upsample(s)).view((b*n,) + self.shape_after_conv)\n",
        "    s = F.relu(self.p_deconv_1(s))\n",
        "    s = F.relu(self.p_deconv_2(s))\n",
        "    s = F.relu(self.p_deconv_3(s))\n",
        "    s = F.relu(self.p_deconv_4(s))\n",
        "    s = self.p_deconv_5(s)\n",
        "    s = self.p_bias(s)\n",
        "    mu_xs = s.view(b, n, -1)\n",
        "    return mu_xs\n",
        "\n",
        "\n",
        "  def decode(self, zs):\n",
        "    # Included for compatability with conv-AE code\n",
        "    return self.generate(zs.unsqueeze(0))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # VAE.forward() is not used for training, but we'll treat it like a\n",
        "    # classic autoencoder by taking a single sample of z ~ q\n",
        "    phi = self.infer(x)\n",
        "    zs = rsample(phi, 1)\n",
        "    return self.generate(zs).view(x.size())\n",
        "\n",
        "\n",
        "  def elbo(self, x, n=1):\n",
        "    \"\"\"Run input end to end through the VAE and compute the ELBO using n\n",
        "    samples of z\n",
        "    \"\"\"\n",
        "    phi = self.infer(x)\n",
        "    zs = rsample(phi, n)\n",
        "    mu_xs = self.generate(zs)\n",
        "    return log_p_x(x, mu_xs, self.log_sig_x.exp()) - kl_q_p(zs, phi)\n",
        "\n",
        "\n",
        "def expected_z(phi):\n",
        "  return phi[:, :-1]\n",
        "\n",
        "\n",
        "def rsample(phi, n_samples):\n",
        "  \"\"\"Sample z ~ q(z;phi)\n",
        "  Ouput z is size [b,n_samples,K] given phi with shape [b,K+1]. The first K\n",
        "  entries of each row of phi are the mean of q, and phi[:,-1] is the log\n",
        "  standard deviation\n",
        "  \"\"\"\n",
        "  b, kplus1 = phi.size()\n",
        "  k = kplus1-1\n",
        "  mu, sig = phi[:, :-1], phi[:,-1].exp()\n",
        "  eps = torch.randn(b, n_samples, k, device=phi.device)\n",
        "  return eps*sig.view(b,1,1) + mu.view(b,1,k)\n",
        "\n",
        "\n",
        "def train_vae(vae, dataset, epochs=10, n_samples=1000):\n",
        "  opt = torch.optim.Adam(vae.parameters(), lr=1e-3, weight_decay=0)\n",
        "  elbo_vals = []\n",
        "  vae.to(DEVICE)\n",
        "  vae.train()\n",
        "  loader = DataLoader(dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
        "  for epoch in trange(epochs, desc='Epochs'):\n",
        "    for im, _ in tqdm(loader, total=len(dataset) // 64, desc='Batches', leave=False):\n",
        "      im = im.to(DEVICE)\n",
        "      opt.zero_grad()\n",
        "      loss = -vae.elbo(im)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "      elbo_vals.append(-loss.item())\n",
        "  vae.to('cpu')\n",
        "  vae.eval()\n",
        "  return elbo_vals\n",
        "\n",
        "\n",
        "convVAE = ConvVarAutoEncoder(K=K_VAE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfCmpcBv8Dlt",
        "outputId": "dc496d8c-9bc5-43c1-e29a-9ac8dfb68fe1"
      },
      "source": [
        "convVAE"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvVarAutoEncoder(\n",
              "  (q_bias): BiasLayer()\n",
              "  (q_conv_1): Conv2d(1, 192, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (q_conv_2): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (q_conv_3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (q_conv_4): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (q_conv_5): Conv2d(512, 768, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (q_flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (q_fc_phi): Linear(in_features=248832, out_features=1025, bias=True)\n",
              "  (p_fc_upsample): Linear(in_features=1024, out_features=248832, bias=True)\n",
              "  (p_unflatten): Unflatten(dim=-1, unflattened_size=(768, 18, 18))\n",
              "  (p_deconv_1): ConvTranspose2d(768, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (p_deconv_2): ConvTranspose2d(512, 384, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (p_deconv_3): ConvTranspose2d(384, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (p_deconv_4): ConvTranspose2d(256, 192, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (p_deconv_5): ConvTranspose2d(192, 1, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (p_bias): BiasLayer()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac8t_FT48Und",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f68cbd1d45854729936ed5e6ac03cc0e",
            "4c1692888d06484a8d2bcc31db7f7d3a",
            "89b4c3ea57704a7f8cb192ce39959b8e",
            "0b2b3afa04cf47498fccf6837f459c4a",
            "8b8ffab1c2ab47b6bcef783ffe691f41",
            "8c4dbba2a81a4e158e505f180e0f9ff3",
            "47d187c6726648c4b114bfe898c29bb3",
            "23834eaa2e7f40c38136cad6ee78654a",
            "3e2bf9383ac64ebca4f89a7b830de90b",
            "ec99a37035a84b86b2ed6dee96c8c91f",
            "509af7c0d85d44a18b55f8dfc8a289f4",
            "db9e31e0fcb4427d92646199bba12387",
            "fef6ef0dc41045f9a9bb93ca1ef283c4",
            "8b0c61d1ec474c708cc92e83c4dbfe7d",
            "78aed0a1d6e2468d8f6fcb767e9817f7",
            "e06e2ac8fac14154a29d229417c7d48a"
          ]
        },
        "outputId": "c3c508ad-08a2-4e87-ae26-b51c07cf6c01"
      },
      "source": [
        "DEVICE = 'cuda'\n",
        "\n",
        "trained_CVAE = train_vae(convVAE, train_set, epochs = 1, n_samples = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f68cbd1d45854729936ed5e6ac03cc0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epochs', max=1.0, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e2bf9383ac64ebca4f89a7b830de90b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=937.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liha1iaE4NsC",
        "outputId": "ab120f13-f97b-4c1e-b483-6b932639b172"
      },
      "source": [
        "p = 0\n",
        "for param in convVAE.parameters():\n",
        "  p += torch.numel(param)\n",
        "\n",
        "p"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "523386147"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8aRD2Cx4XsY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}